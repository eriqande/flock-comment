%!TEX root = flock-comment-main.tex

\section*{Introduction}
In most fields, proposed methods that are 
perceived to be fundamentally novel or new garner more
attention and accolades---and have a higher chance of 
publication---than methods that are clearly minor elaborations upon existing work. 
Not surprisingly, then, in articles and manuscripts, authors may 
emphasize the differences and downplay the similarities between their 
work and the published literature.   In molecular ecology, this 
tendency amongst the creators of statistical methodology can make it 
difficult for end-users to understand the relationship between 
different methods.

Of course, new methods almost always build upon pre-existing ones, and 
much is to be gained by understanding the close relationship between 
different statistical methods in use in molecular ecology today.  
Indeed, some authors downplay the similarities between their method and 
existing ones not because they wish to make their method seem more 
novel, but rather because they are genuinely unaware of the close ties 
between their work and existing methods.  Identifying the 
similarities between new and existing work should help our field
by 1) reducing end-user confusion about whether 
it is necessary to analyze data with a (sometimes overwhelming) variety 
of computer programs; 2) establishing a common language upon which to 
compare different methods; and 3) providing a principled perspective 
from which to argue about the expected strengths and weaknesses of any 
method.

Methods for the unsupervised clustering of genotypes have received 
considerable attention in the molecular ecology literature.  
The best known example of this class of methods is {\sc structure} 
\citep{Pritchardetal2000}.  {\sc structure} itself can be described 
as an elaboration of earlier models used to identify the spawning 
stock of salmon \citep{Smouseetal1990}, and a variety of other 
clustering methods have been developed that are all closely related to 
{\sc structure}, for example {\sc NewHybrids} \citep{And&Tho2002}, {\sc 
BayesAss+} \citep{Wil&Ran2003}, and {\sc baps} 
\citep{Coranderetal2004}. An overview of these similarities can be 
found in \citet{Anderson2009PGAC}.

Recently, a description of the software {\sc flock} was published, 
billing the method as a ``non-Bayesian method [that] 
differs substantially from previous 
clustering algorithms'' \citep[][p.~1333]{Duc&Tur2009}. A following
paper asserts that
\begin{quote}
``{\sc flock} is very different from  other clustering 
programs. It does not sample the space of partitions through small 
random step walks as in MCMC, and it does not try to optimize some 
target function, such as HWLE\@. Briefly stated, it is not based on a 
probabilistic search algorithm. On the contrary, {\sc flock} is 
entirely deterministic'' \citep[][p.~736]{Duc&Tur2012}.
\end{quote}
These papers describe the rationale behind the {\sc flock} algorithm in
intuitive terms with analogies to the coalescence of flocks of birds
or the accretion of snow on a moving snowball.  

Here, we provide a different perspective on the {\sc flock} algorithm,
showing it to be a special, restricted case of the simulated annealing
algorithm for finding the Bayesian maximum {\em a posteriori}
estimate from a marginalized form of the {\sc structure} model with no
admixture and non-correlated allele frequencies.  For illustration, we subsequently compare
the results obtained from {\sc flock} and {\sc structure} on a real data
set with $>$2,500 individuals.

\section*{Comparison of methods}
We start with a succinct mathematical description of the {\sc structure}
model, then describe the {\sc flock} algorithm, and finally explain
the close relationship between the two.


\subsection*{{\sc structure}}
In the {\sc structure} model with no admixture, the unknown ``subpopulation'' that the 
$i\thh$ individual ($i=1,\ldots,N)$ belongs to is denoted by $Z_i \in \{1,\ldots,K\}$, 
where $K$ is the 
number of subpopulations (or clusters, as they are often referred to).  
In a diploid individual from cluster $k$, the 
allelic types of the two gene copies at the $\ell\thh$ locus are assumed
to be drawn independently from the vector of allele frequencies at
locus $\ell$ in subpopulation $k$,  $\theta_{k\ell}=(\theta_{k\ell 1},\ldots,\theta_{k\ell A_\ell})$, where 
$A_\ell$ 
denotes the number of alleles observed in the data set at locus $\ell$.
Hence, if $Y_{i\ell}$ denotes a vector of length $A_\ell$ whose components denote the 
number
of copies of each of the $A_\ell$ alleles at locus $\ell$ in a diploid individual $i$, and 
$Z_i=k$, then $Y_{i\ell}$ follows the multinomial distribution of two trials with
$A_\ell$  components and cell probabilities given by the allele frequencies: 
\begin{equation}
(Y_{i\ell}~|~Z_i=k) \sim \mathrm{Mult}_{A_\ell}(2, \theta_{k\ell}).
\end{equation}
In the {\sc structure} model without physical linkage, the genotypes at the loci are assumed to
be independent of one another, so the probability of the genotype data at
all $L$ loci---$Y_i=(Y_{i1},\ldots,Y_{iL})$---is simply a product of multinomial 
probabilities.
In the uncorrelated allele frequencies model, the prior on each $\theta_{k\ell}$ is a
Dirichlet distribution with parameters $(\lambda_{k\ell1},\ldots,\lambda_{k\ell A_
\ell})$,
which are usually all set to a value such as 1 or $1/A_\ell$.  

After initializing the unknown allele frequencies, $\theta = (\theta_1,\ldots,\theta_K)$, to randomly drawn values,
$\theta^{(0)}$, inference in the model proceeds by sampling from the joint posterior of the 
$Z_i$'s and $\theta$ using Gibbs sampling.  That is,
at iteration $t = 0, 1, 2, \ldots$:
\begin{enumerate}
\item each $Z^{(t)}_i$ is updated to $Z^{(t+1)}_i$ by sampling a value from 
the full conditional distribution of $Z_i$ given
$Y_i$ and $\theta^{(t)}$ (the current estimate of the allele frequencies).  This
distribution is found using Bayes' theorem. In {\sc structure}'s formulation, the 
prior probability that $Z_i=k$ is $1/K$ for all $k=1,\ldots, K$.     
\item $\theta^{(t)}$ is updated to $\theta^{(t+1)}$ from its full conditional distribution.  For each 
cluster
$k$ and locus $\ell$, the full conditional for $\theta_{k\ell}$ is independently a 
Dirichlet distribution with parameters $\lambda_{k\ell j} + \#(k,\ell,j)$, for 
$j=1,\ldots, A_\ell$,
where $\#(k,\ell,j)$ is the number of alleles of type $j$ at locus $\ell$ observed in 
individuals with $Z^{(t+1)}_i = k$.   
\end{enumerate}

It will be useful for our comparison with {\sc flock} to point out that another way 
of pursuing inference in this model would be to first integrate out the 
Dirichlet priors on the allele frequencies and then sample from the posterior
for the $Z_i$'s by Gibbs sampling.  When $\theta$ is integrated out, the genotypes 
of the individuals are no longer conditionally independent (they were originally
independent {\em conditional} on $\theta$ and the $Z_i$'s), so the calculation of 
the full conditional distribution of $Z_i$ becomes somewhat more involved,
but can be computed by the following reasoning. First, the 
conditional distribution of $Y_{i\ell}$, given that individual $i$ is from subpopulation $k$
(\ie $Z_i=k$), depends on the 
cluster memberships and genotypes  of all the remaining individuals,
which we denote by  $Z_{(-i)}$ and $Y_{(-i)\ell}$, respectively.
This full conditional for $Y_{i\ell}$ follows 
a Compound Dirichlet Multinomial distribution (CDM):
\begin{eqnarray}
\lefteqn{(Y_{i\ell}~|~Z_i=k,~Z_{(-i)},~Y_{(-i)\ell}) \sim} \label{eq:cdm}\\
& & \mathrm{CDM}(\lambda_{k\ell 1} + \#_{(-i)}(k,\ell,1), \ldots,
\lambda_{k\ell A_\ell} + \#_{(-i)}(k,\ell,A_\ell)), \nonumber
\end{eqnarray}
where $\#_{(-i)}(k,\ell,j)$ is the number of alleles of type $j$ at locus $\ell$
found in individuals {\em other than individual $i$} that currently
belong to cluster $k$. Thus, calculating (\ref{eq:cdm}) for each value of $Z_i=k \in 
\{1,\ldots,K\}$ 
and normalizing to sum to one gives the full conditional distribution for 
$Z_i$:
\begin{equation}
P(Z_i=k~|~Y_i, ~Z_{(-i)},~Y_{(-i)\ell})~~,~~k=1,\ldots,K.
\label{eq:fc}
\end{equation}
A new value of $Z_i$ would be drawn from (\ref{eq:fc}) if doing Gibbs sampling in this
version of the {\sc structure} model in which $\theta$ has been integrated out.  In 
fact,
this is the approach (with a slightly different prior weight on the $Z_i$'s) taken to 
update 
$Z_i$ in both {\sc hwler} \citep{Pel&Mas2006} and {\sc structurama} \cite{Hue&And2007} 
when not
proposing changes to the number of clusters.



\subsection*{{\sc flock}}
Here we translate the recipe given by \citeauthor{Duc&Tur2009} for the 
{\sc flock} algorithm into a specification in terms of the variables
defined in the previous section.  We provide the description for a case in which
it is assumed there are $K$ clusters.

The first step of the flock algorithm is initialization, during which 
the program randomly allocates each of the $N$ individuals to one of 
$K$ clusters.  Then a number of reallocation steps are performed.  During every one of 
these steps, each individual is given the chance to be reallocated 
(\ie moved to a different cluster).  This is done on the basis of 
maximum likelihood: as \citeauthor{Duc&Tur2009} say (2009, p.~1335), ``Re-allocations are 
performed following multilocus maximum likelihood (Paetkau et al. 1995).''

From that description, it is not clear how \citeauthor{Duc&Tur2009} treat 
alleles that appear in the focal
individual but do not appear within any other individuals within a cluster.
The original approach of \citet{Paetkauetal1995} merely added 0.01 or some other
small value to each allele frequency that was 0, and then renormalized 
the allele frequencies to sum to 1.  In later works, Paetkau and colleagues
also employed the ``Bayesian'' approach of \citet{Ran&Mou1997} in their 
software {\sc geneclass2}  \citep{Piryetal2004}.  If \citeauthor{Duc&Tur2009}
use the approach of \citet{Ran&Mou1997}, then the $i\thh$ individual will
be reallocated to whichever cluster gives the highest value to 
$P(Y_{i\ell}~|~Z_i=k,~Z_{(-i)},~Y_{(-i)\ell})$, which is exactly the probability
defined in (\ref{eq:cdm}).  
If \citeauthor{Duc&Tur2009} use the simpler ``add 0.01 and renormalize''
formulation of \citet{Paetkauetal1995}, then their reallocations are based
on maximizing a likelihood that, although it may not be formally identical to
that in (\ref{eq:cdm}), is nearly identical to it.   

It is worth pointing out that, since the
{\sc structure} model without admixture assumes a uniform prior over 
the $K$ different clusters, $P(Y_{i\ell}~|~Z_i=k,~Z_{(-i)},~Y_{(-i)\ell})$
is exactly proportional to $P(Z_i=k~|~Y_i, ~Z_{(-i)},~Y_{(-i)\ell})$, which 
we have shown is the
full conditional distribution for $Z_i$ in the {\sc structure} model after
integrating out $\theta$.  Thus, we have shown that, doing Gibbs
sampling for $Z_i$ in  the {\sc structure} model in which $\theta$ has been
integrated out would involve sampling a new value of $Z_i$ from the 
probability distribution,
\[
P(Z_i=k~|~Y_i, ~Z_{(-i)},~Y_{(-i)\ell})
\]
and that the updates that
{\sc flock} makes to each $Z_i$ involve assigning to $Z_i$
\begin{equation}
\arg\max_k P(Z_i=k~|~Y_i, ~Z_{(-i)},~Y_{(-i)\ell}),
\end{equation}
\ie the value of $k$ that maximizes $P(Z_i=k~|~Y_i, ~Z_{(-i)},~Y_{(-i)\ell})$
(or, as stated above, a nearly identical function of $k$, depending on how
the program {\sc flock} treats alleles that are not observed in certain clusters).






\subsection*{{\sc flock} as a special case of {\sc structure}}
The goal of {\sc structure}'s MCMC algorithm is to sample from the space of 
$Z$'s in proportion to their posterior probability.  If, all that was desired
was a point estimate of the $Z_i$'s that maximized the posterior probability,
then one standard approach to finding that maximum {\em a posteriori}, or MAP, 
estimate, would be to use simulated annealing \citep{Kirkpatricketal1983}.
To do simulated annealing in the {\sc structure} model with no admixture and
no correlated allele frequency prior, after integrating out the unknown
allele frequencies, the updates for each $Z_i$ would be made from the 
distribution
\[
\biggl[P(Z_i=k~|~Y_i, ~Z_{(-i)},~Y_{(-i)\ell})\biggr]^\beta
\]
which is the same full conditional distribution as the marginalized {\sc structure}
model (equation~\ref{eq:fc}), raised
to the power $\beta$.  In typical applications of simulated annealing,
$\beta$ is set to a starting value less than 1, and, as the algorithm proceeds,
$\beta$ is increased according to a ``cooling schedule''\citep{Hajek1988}, until
the algorithm finds a local maximum in the posterior probability surface.  
When $\beta$ is small, the process can easily traverse ``valleys''
in the posterior probability surface and has a better chance of searching
more of the space for the maximum value.  As $\beta$ gets larger, it becomes
more probable that the process will
move uphill on the probability surface, tending toward the local
maximum near where it currently is.    

It should now be clear that the algorithm in {\sc flock} is a simulated annealing 
algorithm for the {\sc structure} model in which the cooling schedule is
``start with $\beta\rightarrow\infty$ and leave it there for the duration of 
the algorithm.''  As such, we can expect that it may not provide the best 
mechanism for searching for the MAP estimate and it may be more susceptible 
to becoming trapped in local modes of the posterior probability. 
In the following section we show that {\sc structure} and {\sc flock} find similar
solutions in the analysis of a large microsatellite data set, though, as expected,
{\sc flock} seems to find the same solution less consistently than does {\sc structure}.





\section*{Performance Comparison with {\sc structure}}

\subsection*{Analysis of coastal California steelhead} 
We used a published dataset of 2596 steelhead, \textit{Oncorhynchus mykiss},
genotyped at 15 microsatellite loci from \citet{Garzaetal_norcal} to compare the programs
{\sc flock} and {\sc structure}.  {\sc flock} 
was run six times using the default setting for all 
run parameters (initial partition = random, number of iterations = 20, number of runs = 50, 
LLOD threshold = 0) for values of $K$ from 2 to 6. The stopping point of 
$K=6$ was chosen after four consecutive values of $K$
yielded no plateau (see below). For each value of $K$ from 2 to 6, the no-admixture, 
uncorrelated-allele-frequency model implemented in {\sc structure} was run 6 times with 
a 50,000 sweep burn-in followed by a 150,000 sweep sample from the posterior. 
All runs were performed on a JNCS D685 with an i7 3.40GHz processor and 8GB
of RAM running 64-bit Windows 7. 

For each set of runs, {\sc flock} reports the 
normalized likelihood values (the exponentiated log-likelihood value for an individual's 
membership to each of $K$ clusters, scaled to sum to one) for a run belonging to the longest plateau - refered to as the 'best run' by \citep{Duc&Tur2012} (see below).
These values can be compared to the $q_i$ values
returned by {\sc structure}, which, in the no-admixture case, are posterior probabilities of cluster membership.
The program {\sc clumpp} \citep{Jak&Ros2007} was used to relabel clusters among different runs,
while the program {\sc district} \citep{Rosenberg2004} was used to plot individual \textit{$q_i$} values. 

\citet{Duc&Tur2012} promote a method for using {\sc flock} to estimate, $K$, the number of
subpopulations. The user must specify both the number of runs (different initial allocations of individuals 
to each cluster) as well as the number of iterations. (In each iteration every individual has the opportunity to be reallocated 
to a different cluster.) At the conclusion of each run, the log-likelihood value for membership to all $K$ clusters is computed
and the log likelihood difference (LLOD), the difference between the cluster with the highest likelihood 
and second highest likelihood, is calculated for each individual. {\sc flock} identifies runs that 
have converged to the same solution by detecting that they have the same mean LLOD score, and, in 
{\sc flock} parlance, a series of runs that have converged to the same solution are termed a ``plateau.'' 
The plateau record is a list of how many runs converged to the same allocation
of individuals. 
\citet{Duc&Tur2012} developed two stopping rules that they use to estimate $K$. In the absence of 
strong prior beliefs about the value of $K$, \citet{Duc&Tur2012} advocate running  {\sc flock} until either a single plateau of
$\geq 6$ runs is reached or four consecutive $K$ values yield no plateaus. If the first stopping condition is satisfied,
the $K$ for which there is a single plateau of $\geq 6$ runs is the point estimate for $K$. Alternatively, 
if multiple plateaus are observed with at least one plateau of $\geq 6$ runs, the largest value of $K$ that satisfies 
this conditon should be taken as the lower bound estimate of $K$. If no plateaus of $\geq 6$ runs are observed, $K$
is declared {\em undecided}.  


It is now common practice to use the approximate marginal likelihood ($\ln P(D)$) from {\sc structure}
or a derived quantity such as $\Delta K$ \citep{Evannoetal2005} to try to estimate $K$.
While we take the stance that estimates of $K$ made with {\em any} unsupervised clustering algorithm
from data on real (non-idealized) populations should always be interpreted and used
cautiously, it is nonetheless instructive to compare \citet{Duc&Tur2012}'s method for
estimating $K$ to results obtained using $\ln P(D)$ and $\Delta K$, and we do so, below. 


\subsection*{Results} 
Run times for both programs were relatively short, albeit not trivial. All runs of {\sc flock} 
completed in 1133 minutes. Each of the six groups of runs averaged 188.8 minutes.
All runs of {\sc structure} were completed in 
486 minutes and averaged 80.8 minutes to complete each of the six groups of runs.
The processing time of each algorithm increased as the number or 
putative clusters increases. Increasing
$K$ from of 2 to 6 increased the run time for {\sc flock} by a factor of 2.4, while the run time 
for {\sc structure} increased by a factor of 1.6.

{\sc flock} and {\sc structure} provide similar results in 
terms of how individuals are allocated among runs at low values of $K$, 
while at larger values, {\sc flock} often found, in addition to the solution identified by {\sc structure}, 
multiple other solutions. For all six groups 
of runs with $K = 2$ to 4, {\sc flock} obtained a nearly identical clustering of individuals 
(See supplementary materials) none of which differed substantially from {\sc structure}'s results
(Fig.~\ref{fig:qplots}). Of the ``best runs'' for the six groups for $K$ = 2, two  
runs yielded identical clustering (same mean LLOD score) while all other runs 
differed by at most the allocation of 13 individuals. As 
$K$ increased so did the number of solutions
that {\sc flock} found (Fig 1). For all groups of runs for $K$ $\geq 2$, no plateaus were observed---all intial 
allocations resulted in solutions that differed. 
{\sc flock} still produced estimates of the LLOD by individual for the 
'best run', however, it is unclear in these cases what constitutes the 'best run' as all plateau lengths are 
equal to one. Many of these solutions are, however, surprisingly similar to
the partitions identified by {\sc structure}. Both programs idenfity clusters 
which can be attributed to the geographical boundaries identified by \citet{Garzaetal_norcal},
although less reliably so in the case of {\sc flock}.

Despite the similar allocation of individuals into $K$ clusters, the 
plateau analysis to estimate $K$ in {\sc flock} leads to different conclusions among groups of runs, as well as 
one that differs from {\sc structure}. While no plateaus were observed in any of the six groups 
for a $K\geq 2$, the plateau record varied greatly among each
group for $K = 2$ (plateau sequences: Run1 = 3,2,3,7,4; Run2 = 2,5,2,3,2,3; Run3 = 2,2,2,2,2,5; 
Run4 = 2,3,4,2,4,3; Run5 = 2,2,5,5,3; and; Run6 = 2,2,2,2,2,3,3). The plateau analysis 
procedure suggested by \citet{Duc&Tur2012} leads to
either an estimate of K $\geq$ 2 (Run1) or {\em undecided} as a consequence of no plateau 
lengths being greater than 6. The ($\ln P(D)$) from {\sc structure}
was largest at $K$ = 6 which was further supported by the $q_i$ plots, however,
the $\Delta K$ method supported a $K$ of 3.
 


\begin{figure*}
\begin{center}
	 % NOTE. Eric made Flock-Fig1.jpg as a Preview because Flock-Fig1.pdf
	 % ate up too many resources while editing the document.  For final 
	 % production, it should be changed back to Flock-Fig1.pdf
    \includegraphics[width=\textwidth]{images/Figures-Pat/Flock-Fig1-GreyScale.pdf} % Flock-Fig1.jpg}  
    \caption{Plots of $q_i$ values from {\sc structure} and the normalized likelihood values 
from {\sc flock} made in the program Distruct. Each horizontal plot represents an individual run of the program {\sc structure}, or the 'best run' from a series of runs in {\sc flock}. Within each plot 
$q_i$ values from {\sc structure} and the normalized likelihood values 
from {\sc flock}  are represented by a 
colored vertical bar.  Results from 
from the 'best runs' of {\sc flock} showed similar geographic differentiation to 
\citet{Garzaetal_norcal}.}
    \label{fig:qplots}
\end{center}
\end{figure*}


%\begin{figure}
%\begin{center}
% \includegraphics[width=\columnwidth]{images/Figures-Pat/Fig2.pdf}
%    \caption{Individual \textit{$q_i$} values plotted for each cluster for $K=5$. 
%{\sc flock} estimates of likelihood of assignment to each cluster have less uncertainty
% attributed to them.}
%    \label{fig:qscatter}
%\end{center}
%\end{figure}

To investigate the ability of the arrangement of individuals within the reference 
populations to move around the partition space we varied the number of iterations that 
each run goes through to find the ``optimal'' allocation of individuals. Unfortuantely 
only the reallocation matrix for the ``best run'' is given as output. Increasing the 
number of iterations did not affect the overall inference of $K$. We 
observed that often during the last iterations individuals would alternate between 
reference groups. Increasing the log likelihood 
difference threshold for reallocation to 0.18 (requiring at least a 1.5 times 
higher likelihood to reallocate the individual) minimized this, but did not affect the 
inference of $K$ (lower bound estimate of $K = 2$).

\section*{Conclusions}
In the past decade, the use of genetic markers to identify population structure and to attempt inference of
the number of genetic clusters ($K$) in a collection has dramatically increased in the fields of ecology, evolution, epidemiology, and conservation
genetics. By virtue of this expanding desire to identify $K$ there has been a push to 
develop fast and easy-to-use methods that can accurately infer $K$. We show that {\sc flock}, a program billed as providing
``more accurate allocations and more reliable estimates of $K$ [while running]
much faster than {\sc structure} \citep[][p.~734]{Duc&Tur2012},'' may not, in fact, represent such 
a radical departure from {\sc structure} itself.  In particular, we have shown that the algorithm implemented 
in {\sc flock} is a simulated annealing algorithm for the Bayesian 
MAP estimate from a marginalized and restricted form of the {\sc structure} model.  
Given such similarities between the two methods it is not surprising that
we observed relatively
congruent results between the ``best run'' from {\sc flock} and {\sc structure} using 
a real data set from \textit{O. mykiss}.


Though we observed very similar results
between the two programs at low values of $K$, {\sc flock} had a tendency to provide inconsistent solutions
among its ``best runs'' at higher values of $K$, while still finding solutions that were similar to {\sc structure}'s.
This is likely a consequence of the rapidly increasing size of the search space over possible 
partitions as $K$ and $n$, the number of individuals, increase. 
The likelihood surface defined on partitions of this space is likely to be
be characterized by multiple peaks and troughs.
The peak that  {\sc flock}'s deterministic algorithm finds is entirely dependent on the initial allocation of 
individuals, as it has no way to visit areas of the surface with smaller likelihood values.
If the number of initial allocations does not increase
as $K$ is increased, the starting allocations become diffusely scattered in the space of all
possible partitions making it unlikely that many (if any at all) will converge to the same local mode. This coupled with the fact that there is 
ambiguity in what defines a ``best run'' when all plateaus are of length zero complicates the interpretation
of results from {\sc flock} if no non-zero plateaus are encountered.

One of the major claimed advantages of {\sc flock} over other methods for genetic clustering (like {\sc structure})
is that, ``The very short processing times for each run of {\sc flock} allows for
comparing partitions from many runs of each $K$'' \citep[][p.~735]{Duc&Tur2012}.
While \citeauthor{Duc&Tur2012} observed faster processing times (relative to other methods) in their 
comparisons, we did not observe the same advantage in our analysis. This appears to result from two issues. First,
our example data set was an order of magnitude larger than the largest data set analyzed in \citet{Duc&Tur2012}.  Second, 
in the comparison by \citet{Duc&Tur2012}, 
{\sc flock} was set to perform 50 runs and 20 iterations for each $K$ from 1 to four more than 
the true value of $K$, and computing times for that analysis were compared to times for ten iterations of {\sc structure} using 
a 50,000 sweep burn-in followed 
by a 200,000 sweep sample from the posterior for values of $K$ from 1 to three more than the true 
value of $K$. 
To us it seemed reasonable to compare, for each $K$, one iteration of {\sc structure} (50,000 burn in and 200,000 sample collection sweeps)
to one iteration of {\sc flock} (50 different starting allocations that are reallocated 20 times) 
as both are used to provide a single estimate of the partition of individuals into clusters. One could
argue that it would be more appropriate to compare the running times of the programs according to the number
of opportunities that each individual's cluster membership has for random initialization and reallocation.  Under 
such a perspective, {\sc flock}'s 50 different starting allocations and 20 reallocations should be compared to
50 separate runs of structure, each of length 20 sweeps, which would surely give {\sc structure}
an apparent advantage in speed.  Regardless, we did not find a speed advantage from using {\sc flock}.
If anything, {\sc structure} was somewhat faster.


For those that do decide to use {\sc flock} as an alternative to {\sc structure}, the {\em ad hoc} rules 
to estimate $K$ may be overly stringent. While there has been lengthy 
discourse over the choice of estimators for $K$ in {\sc structure} \citep{Pritchardetal2000,Evannoetal2005,Wap&Gag2006,Gaoetal2011} much less effort has been put forth examining how the number of individuals
and the number of starting allocations can affect not only the convergence of different runs of {\sc flock}, but also its 
inference of $K$. \citeauthor{Duc&Tur2012} developed estimation rules based on simulated data 
sets with a modest number of individuals and different migration regimes and rates, number of loci, and $K$. 
By relying on identical allocations (mean LLOD values) as a means of supporting 
a particular $K$,  similar---but not identical---allocations
will provide no support to a given $K$. If using {\sc flock}, we advise running
multiple small batches and using the programs {\sc clumpp} \citep{Jak&Ros2007} and
{\sc distruct} \citep{Rosenberg2004} to visually inspect the ``best run'' results.  

For many types of genetic analyses, molecular ecologists can choose from 
amongst a wide range of published methods.  Choosing one of these methods to use can
be difficult, especially when the methods have been touted as very different.
We have known colleagues whose solution to this problem is simply to run their data
through every program available.  This seems an ineffective use of time and resources 
that could be counteracted by a more transparent accounting of the similarities between
methods. As one small step toward that,   
we have provided a different perspective on the algorithm
implemented in {\sc flock}, showing it to be very similar to {\sc structure}
using a particular set of options.  We hope this might increase understanding of {\sc flock}'s applicability to different datasets while decreasing end user confusion and misuse. 



 
